import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sns
import statsmodels.formula.api as smf

from sklearn.model_selection import train_test_split

from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

pd.set_option('display.max_columns', None)

nba = pd.read_csv("2023-2024 NBA Player Stats - Playoffs.csv", sep=";")
nba = nba.drop(columns = "Rk")
nba

#Filter out players that played a small amount of minutes as their stats aren't valuable information
rotation = nba[nba["MP"]>=15]
rotation

#Four single variable plots
rotation["PTS"].hist(bins=30)
plt.xlabel("Points Per Game")
plt.ylabel("# of Players")
plt.title("Points Per Game Distribution")

rotation["FG%"].hist(bins=30)
plt.xlabel("Field Goal Percentage")
plt.ylabel("# of Players")
plt.title("Distribution of Field Goal Percentage")

rotation["3P%"].hist(bins=30)
plt.xlabel("Three Point Percentage")
plt.ylabel("# of Players")
plt.title("Distribution of Three Point Percentage")

rotation["FT%"].hist(bins=30)
plt.xlabel("Free Throw Percentage")
plt.ylabel("# of Players")
plt.title("Distribution of Free Throw Percentage")

def front_or_back(x):
    if x=="PG" or x=="SG":
        return "Guards"
    elif x=="SF" or x=="PF":
        return "Forwards"
    else:
        return "Center"

rotation.loc[:,"General_Pos"]=rotation["Pos"].apply(front_or_back)

#Two multi-variable plots
sns.relplot(x="PTS", y="3PA", hue="Genral_Pos", data=rotation).fig.set_size_inches(8,9)
plt.xlabel("Avg Points Per Game")
plt.ylabel("Avg Three-Pointers Attempted Per Game")
plt.title("Relationship Between Points Per Game and Three-Pointers Attempted")

plt.figure(figsize=(8,7))
sns.regplot(x="AST", y="TOV", data=rotation)
plt.xlabel("Avg Asists Per Game")
plt.ylabel("Avg Turnovers Per Game")
plt.title("Relationship Between Average Asists Per Game and Turnovers")

#Machine Learning model 1: K-Nearest Neighbors
#Drop player column since it isn't data and will create too many dummies
#Convert qualitative columns into dummies
rotation_dummy = rotation.drop(columns="Player")
rotation_dummy = pd.get_dummies(rotation_dummy, columns=["Pos", "Tm", "General_Pos"], drop_first = True)

#create variable, x, with all columns except dependent variable
x = rotation_dummy.drop(columns="PTS")
x.head()

#create variable with dependent variable
y = rotation_dummy["PTS"]
y.head()

#split data into testing and training data
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)

#Create K Nearest Neighbors model and fit training data into the model
knn = KNeighborsRegressor(n_neighbors=5)
knn.fit(x_train, y_train)

#Use the testing data to predict the dependent variable(pts)
y_test_pred = knn.predict(x_test)
y_test_pred

#Calculate the MSE
mean_squared_error(y_test_pred, y_test)

#For loop computing mean squared error for k values 1-10
for k in range(1,11):
    knn = KNeighborsRegressor(n_neighbors=k)
    knn.fit(x_train, y_train)
    y_test_pred = knn.predict(x_test)
    mse = mean_squared_error(y_test_pred, y_test)
    print("MSE for ", k, ": ", mse)
    
    #For loop so white space and colons are alligned
    if k<10:
        print("MSE for  ", k, ": ", mse)
    else:
        print("MSE for ", k, ": ", mse)

#Model 2: Decision Tree models
dt3 = DecisionTreeRegressor(max_depth=3)
dt3.fit(x_train,y_train)

y_dt3_pred = dt3.predict(x_test)
y_dt3_pred

mean_squared_error(y_dt3_pred, y_test)

#Same for loop as K-Nearest
dt_mses=[]
for k in range(1,13):
    dt = DecisionTreeRegressor(max_depth=k)
    dt.fit(x_train, y_train)
    y_dt_pred = dt.predict(x_test)
    dt_mse = mean_squared_error(y_dt_pred, y_test)
    dt_mses.append(dt_mse)

    if k<10:
        print("MSE for k value ",k,": ", dt_mse)
    else:
        print("MSE for k value",k,": ", dt_mse)

best_fit_dt = DecisionTreeRegressor(max_depth=4)
best_fit_dt.fit(x_train, y_train)

fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (10,10), dpi=600)
plot_tree(best_fit_dt, feature_names = x.columns)

pd.Series(knn_mses).min()

pd.Series(dt_mses).min()
